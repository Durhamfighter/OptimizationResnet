{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np \n",
    "import os\n",
    "import joblib\n",
    "import torch.nn.utils.prune as prune\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # Resize to 224x224\n",
    "    transforms.ToTensor(),   # Convert image to PyTorch Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet stats\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.CIFAR10(root=\"./data\", train=False, transform=transform, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## utils 에넣기\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# For GPU\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "##args path에 넣기\n",
    "saved_path= '/data/ephemeral/home/nathan/saved'\n",
    "model_name=os.path.join(saved_path,'resnet18.joblib')\n",
    "model = joblib.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args 와 criterion에 넣기\n",
    "# Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 풀더에 넣고 모듈화진행 \n",
    "def train(model,train_loader,num_epochs=10):\n",
    "    model.train()\n",
    "    for epochs in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss=0.0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images,labels= images.to(device),labels.to(device)\n",
    "\n",
    "            output=model(images)\n",
    "            loss = criterion(output,labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss+=loss.item()\n",
    "\n",
    "        print(f'Epochs: {epochs+1}/{num_epochs} Training loss: {running_loss/len(train_loader)}')\n",
    "        \n",
    "def test(model,test_loader,howmany):\n",
    "    model.eval()\n",
    "    s=time.time()\n",
    "    with torch.no_grad():\n",
    "        total=0\n",
    "        correct=0\n",
    "        for images,labels in tqdm(test_loader):\n",
    "            images,labels= images.to(device),labels.to(device)\n",
    "            output=model(images)\n",
    "            _,predicted = torch.max(output,dim=1)\n",
    "            total+=labels.size(0)\n",
    "            correct+=(predicted==labels).sum().item()\n",
    "        \n",
    "        accuracy=100*correct/total\n",
    "        e=time.time()\n",
    "        print(f'Accuracy: {accuracy}%, Forward Time: {e - s:.2f}s, pruned_channel: {howmany}')\n",
    "        get_model_memory_usage(model)\n",
    "\n",
    "def get_model_memory_usage(model):\n",
    "    total_params = 0\n",
    "    total_memory = 0\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            total_params += param.numel()\n",
    "            total_memory += param.numel() * param.element_size()  # Bytes\n",
    "\n",
    "    print(f\"Total Parameters: {total_params}\")\n",
    "    print(f\"Memory Usage for Parameters: {total_memory / 1e6:.2f} MB\")  # Convert to MB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured pruning for CNN 은 2가지로 구분된다\n",
    "1. CNN (연산속도)-> 학습된 모델에 sentiment analysis 요구 (Filter, )\n",
    "2. FN (파라미터) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sensitivity analysis\n",
    "sensitivity_layer={}\n",
    "for name,module in model.named_modules():\n",
    "    if isinstance(module,nn.Conv2d):\n",
    "        L1_weight= module.weight.data.cpu().numpy()\n",
    "        L1_weight=L1_weight.reshape(L1_weight.shape[0],-1)\n",
    "        L1_weight=np.sort(np.sum(np.abs(L1_weight),axis=1))[::-1]\n",
    "        L1_weight=L1_weight/L1_weight[0]\n",
    "        #L2_weight = torch.sqrt(torch.sum(module.weight,dim=(1,2,3)))\n",
    "        sensitivity_layer[name]=L1_weight\n",
    "        \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sensitivity CNN 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "colors = ['r', 'g', 'b', 'k', 'y', 'm', 'c']\n",
    "lines = ['-', '--', '-.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "count=0\n",
    "for key,sensitivity in sensitivity_layer.items():\n",
    "    line_style=colors[count%len(colors)]+lines[count//len(colors)]\n",
    "    x=np.linspace(0,100,num=sensitivity.shape[0])\n",
    "    y=sensitivity\n",
    "    count+=1\n",
    "    print(count)\n",
    "    plt.plot(x,y,line_style,label='conv %d'%count)\n",
    "plt.ylabel(\"normalized abs sum of filter weight\")\n",
    "plt.xlabel(\"filter index / # filters (%)\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlim([0, 140])\n",
    "plt.grid()\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prune 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ratio=0.9\n",
    "step_ratio=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2name_module={}\n",
    "i=0\n",
    "for name,module in model.named_modules():\n",
    "    if isinstance(module,nn.Conv2d) and 'downsample' not in name:\n",
    "        idx2name_module[i]=(name,module)\n",
    "        i+=1\n",
    "    elif isinstance(module,nn.BatchNorm2d) and 'downsample' not in name:\n",
    "        idx2name_module[i]=(name,module)\n",
    "        i+=1\n",
    "    elif isinstance(module,nn.Linear):\n",
    "        idx2name_module[i]=(name,module)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prune_function import *\n",
    "from prune import *\n",
    "idx=0\n",
    "for name,module in model.named_modules():\n",
    "    if isinstance(module,nn.Conv2d) and 'downsample' not in name:\n",
    "        step=np.linspace(0,int(module.out_channels*max_ratio),step_ratio,dtype=int)\n",
    "        steps=step[1:]-step[:-1]\n",
    "        # steps는 얼마만큼의 filter를 제거할꺼인지 정함.\n",
    "        for i in range(len(steps)//2): \n",
    "            # 매번 필터를 제거하는양이 달라서 network부름\n",
    "            network=joblib.load(model_name)\n",
    "            num_channel=module.out_channels- sum(steps[:i+1])\n",
    "            print(name,sum(steps[:i+1]))\n",
    "            network=prune_step(network,name,num_channel,idx2name_module,index=idx).to(device)\n",
    "            print(\"-*-\"*10 + \"\\n\\tPrune network\\n\" + \"-*-\"*10)\n",
    "            print(network)\n",
    "            \n",
    "            network_name_v='resenet'+'_'+ name +'_'+str(sum(steps[:i+1]))+'.joblib'\n",
    "            network_name=os.path.join(saved_path,network_name_v)\n",
    "\n",
    "            #joblib.dump(network,network_name)\n",
    "            test(network,test_loader,sum(steps[:i+1]))\n",
    "        idx+=2\n",
    "                \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prune_function import *\n",
    "from prune import *\n",
    "name,module=idx2name_module[12]\n",
    "step=np.linspace(0,int(module.out_channels*max_ratio),step_ratio,dtype=int)\n",
    "steps=step[1:]-step[:-1]\n",
    "# steps는 얼마만큼의 filter를 제거할꺼인지 정함.\n",
    "for i in range(len(steps)//2): \n",
    "    # 매번 필터를 제거하는양이 달라서 network부름\n",
    "    network=joblib.load(model_name).to('cpu')\n",
    "    num_channel=module.out_channels- sum(steps[:i+1])\n",
    "    print(name,sum(steps[:i+1]))\n",
    "    network=prune_step(network,name,num_channel,idx2name_module,index=idx).to(device)\n",
    "    print(\"-*-\"*10 + \"\\n\\tPrune network\\n\" + \"-*-\"*10)\n",
    "    print(network)\n",
    "    \n",
    "    network_name_v='resenet'+'_'+ name +'_'+str(sum(steps[:i+1]))+'.joblib'\n",
    "    network_name=os.path.join(saved_path,network_name_v)\n",
    "\n",
    "    #joblib.dump(network,network_name)\n",
    "    test(network,test_loader,sum(steps[:i+1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aitech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
